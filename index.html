<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head>
    <meta charset="utf-8">
    <meta name="description" content="OPA-DPO">
    <meta name="keywords" content="OPA-DPO, open-source, vision-language, MLLM, LVLM, hallucination">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>OPA-DPO</title>
  
    <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0">
  
    <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="icon" href="images/icon.jpg">
    <link rel="stylesheet" href="./static/css/index.css">
  
    <link rel="shortcut icon" href="images/icon.jpg" type="image/x-icon">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer="" src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
  
      #main{
          position: relative;;
          width: 1200px;
      }
  
      .box{
          float: left;
          padding: 15px 0 0 15px;
  /*        background-color: red;*/
      }
  
      .pic{
          width: 500px;
          padding: 10px;
          border: 1px solid #ccc;
          border-radius: 5px;
          background-color: #fff;
      }
  
      .pic img{
          width: 500px;
      }
  
    </style></head>
  
    
  
  
  
    <body>
  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">[CVPR 2025 <a style="color:red">Oral (0.74%)</a>]</h1>
            <h1 class="title is-1 publication-title">OPA-DPO</h1>
            <h2 class="title is-3 publication-title">Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key</h2>
            <div class="is-size-5">
              <span class="author-block">
                <a href="https://zhyang2226.github.io" style="color:#008AD7;font-weight:normal;">Zhihe Yang<sup>1,3</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://www.microsoft.com/en-us/research/people/xufluo/" style="color:#008AD7;font-weight:normal;">Xufang Luo<sup>2*</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://www.microsoft.com/en-us/research/people/dongqihan/" style="color:#008AD7;font-weight:normal;">Dongqi Han<sup>2</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://www4.mae.cuhk.edu.hk/peoples/xu-yunjian/" style="color:#008AD7;font-weight:normal;">Yunjian Xu<sup>1,3*</sup></a>,
              </span>
              <span class="author-block">
                <a href="http://recmind.cn/" style="color:#008AD7;font-weight:normal;">Dongsheng Li<sup>2</sup></a>,
              </span>
            </div>
  
            <br>
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#c200f2; font-weight:normal">▶ </b>1. The Chinese University of Hong Kong, Hong Kong SAR, China. </span>
  
            <br>
              <span class="author-block"><b style="color:#00A4EF; font-weight:normal">▶ </b>2. Microsoft Research Asia, Shanghai, China. </span>

            <br>
              <span class="author-block"><b style="color:#c200f2; font-weight:normal">▶ </b>3. The Chinese University of Hong Kong, Shenzhen Research Institute (SZRI), Guangdong, China. </span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Corresponding authors</span>
            </div>
  
            <br>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2501.09695" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
  
                <span class="link-block">
                  <a href="https://github.com/zhyang2226/OPA-DPO" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Code</span>
                    </a>
                </span>
  
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1Xmrb43zIbk3IzLLRQx65iBf7J4SHXa9j" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-database fa-w-14" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="database" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M448 73.143v45.714C448 159.143 347.667 192 224 192S0 159.143 0 118.857V73.143C0 32.857 100.333 0 224 0s224 32.857 224 73.143zM448 176v102.857C448 319.143 347.667 352 224 352S0 319.143 0 278.857V176c48.125 33.143 136.208 48.572 224 48.572S399.874 209.143 448 176zm0 160v102.857C448 479.143 347.667 512 224 512S0 479.143 0 438.857V336c48.125 33.143 136.208 48.572 224 48.572S399.874 369.143 448 336z"></path></svg><!-- <i class="fa fa-database"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Datasets</span>
                    </a>
                </span>
  
               <span class="link-block">
                 <a href="https://huggingface.co/zhyang2226/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                   <span class="icon">
                     <svg class="svg-inline--fa fa-laugh fa-w-16" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="laugh" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm80 152c17.7 0 32 14.3 32 32s-14.3 32-32 32-32-14.3-32-32 14.3-32 32-32zm-160 0c17.7 0 32 14.3 32 32s-14.3 32-32 32-32-14.3-32-32 14.3-32 32-32zm88 272h-16c-73.4 0-134-55-142.9-126-1.2-9.5 6.3-18 15.9-18h270c9.6 0 17.1 8.4 15.9 18-8.9 71-69.5 126-142.9 126z"></path></svg><!-- <i class="fa fa-laugh"></i> Font Awesome fontawesome.com -->
                   </span>
                   <span>Models</span>
                   </a>
               </span>
  
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p>
              Thanks for your interest in our work. Currently, the number of users has exceeded our expectations. We provide <strong><font color="#008AD7">alternative demo links</font></strong> here:
              <a href="https://b2517615b965687635.gradio.live" target="_blank">Demo1</a>
              <a href="https://c8de8ff74b6a6c6a9b.gradio.live" target="_blank">Demo2</a>
              <a href="https://90bc0bac96e6457e8f.gradio.live" target="_blank">Demo3</a>
              <a href="https://cd772059965a71f9e6.gradio.live" target="_blank">Demo4</a>
              <a href="https://48da7e23bcadec7551.gradio.live" target="_blank">Demo5</a>
              <a href="https://687d119023cd37e5fb.gradio.live" target="_blank">Demo6</a>
              <a href="https://0810e8582bcad31944.gradio.live" target="_blank">Demo7</a>
              <a href="https://31c7cdb7e3594e851e.gradio.live" target="_blank">Demo8</a>
  
              <strong><font>News</font></strong>: We now provide a pretrained MiniGPT-4 aligned with <strong><font color="#008AD7">Vicuna-7B</font></strong>! The demo GPU memory consumption now can be <strong><font color="#008AD7">as low as 12GB</font></strong>.
              <br>
              </p>
          </div>
        </div>
      </div>
  </section>
   -->
  
  <!-- <link rel="stylesheet" href="js/ft-carousel.css" />
  <script src="js/jquery.min.js"></script>
  <script src="js/ft-carousel.min.js"></script>
  <script type="text/javascript">
    $("#carousel_1").FtCarousel();
  
    $("#carousel_2").FtCarousel({
      index: 1,
      auto: false
    });
  
    $("#carousel_3").FtCarousel({
      index: 0,
      auto: true,
      time: 3000,
      indicators: false,
      buttons: true
    });
  </script> -->
  
  <!--
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
         <div class="item">
          <img src="demos/wop_2.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
          </h2>
        </div>
        <div class="item">
          <img src="demos/cook_1.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
          </h2>
        </div>
        <div class="item">
          <img src="demos/fix_1.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
         </h2>
       </div>
       <div class="item">
        <img src="demos/rhyme_1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </div>
  </div>
  </section>
   -->
  
  <link rel="stylesheet" type="text/css" href="js/simple_style.css">
  <script type="text/javascript" src="js/simple_swiper.js"></script>
  
  
  <!-- <div class="app">
    <div id="swiper-demo" class="simple-swiper-container">
      <a id="prev" class="btn btn-prev"></a>
      <a id="next" class="btn btn-next"></a>
      <div class="pagination"></div>
    </div>
  </div>
  <p id="index"></p>
  
  <script type="text/javascript">
    new SimSwiper("#swiper-demo", {
      autoplay: 4000,
      duration: 300,
      easing: 'ease',
      button: {
        prev: "#prev", // 前进后退按钮
        next: "#next"
      },
      pagination: {
        el: '.pagination',
        click: true// 是否可以点击
      },
      // 轮播图数据
      data: [{
        index: 0,
        href: '#',
        src: 'demos/wop_2.png'
      }, {
        index: 1,
        href: '#',
        src: 'demos/cook_1.png'
      }, {
        index: 2,
        href: '#',
        src: 'demos/fix_1.png'
      }, {
        index: 3,
        href: '#',
        src: 'demos/rhyme_1.png'
      }]
    });
  </script> -->
  
  
  <section class="section interpolation-panel">
    <div class="container">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-10">
          <br>
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified" style="font-size: large;">
            <p>
                <b>Hallucination</b> remains a major challenge for Large Vision-Language Models (<b>LVLMs</b>), also referred to as Multimodal Large Language Models (<b>MLLMs</b>). 
                Direct Preference Optimization (<b><a href="https://arxiv.org/abs/2305.18290" target="_blank">DPO</a></b>) has gained increasing attention as a simple solution to hallucination issues. It directly learns from constructed preference pairs that reflect the severity of hallucinations in responses to the same prompt and image.
                Nonetheless, we noticed that <span style="color:rgb(255, 0, 0);">different data construction methods in existing works bring notable performance variations</span>. 
                Furthermore, we have uncovered the underlying reasons for these variations from a theoretical perspective.
                In short, our contributions are as follows:
              </p><ul>
                <li>
                    <b>Systematic Review:</b> We present a comprehensive review of existing DPO-based algorithms for mitigating hallucination issues and highlight their limitations.
                </li>
                <li>
                    <b>Crucial Factor Idenfication:</b> From theoretical perspective, we identify that outcomes are highly dependent on whether the constructed data aligns on-policy with the initial (reference) policy of DPO.
                </li>
                <li>
                    <b>SOTA Algorithm:</b> Building upon the limitations of existing methods, we propose a simple yet highly effective algorithm, <span style="color:rgb(255, 0, 0);">On-Policy Alignment (OPA)-DPO</span>, which achieves SOTA performance with only 4.8k data, while the previous SOTA one requires 16k.
                </li>
              </ul>
            <p></p>
          </div>
        </div>
      </div>
      <br>
    </div>
  </section>
  
      
  <section class="section">
    <div class="container is-max-desktop">
      <!--/ Paper video. -->
      <br>
      <br>
      <!-- Paper Model. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Introduction</h2>
            <div class="content has-text-justified">
                <p>
                <b style="font-size: larger;">Motivation and Performance Summary</b>:
                </p>
                <p>
                  To mitigate hallucinations in LVLMs (or MLLMs) with DPO, 
                  the most effective approach would be to have the model generate a response based on a given prompt and image, 
                  followed by experts correcting hallucinations in the generated content to construct preference pairs. 
                  However, in practice, even when these corrections are minor, the corrected responses are often off-policy relative to the original model 
                  (i.e., they have extremely low sampling probabilities).
                  We reveal a key point that are often neglected in existing works:
                  <span style="color:rgb(255, 0, 0);">the off-policy prefferred response can <b>NEVER</b> be learnt by the models due to the implicit KL constraints.</span>
                  Based on this observation, we propose <b style="color:rgb(255, 0, 0);">OPA-DPO</b>, which aligns the constructed data on-policy before DPO training.
                  Experimental results demonstrate that OPA-DPO significantly improves performance by incorporating the OPA operation and achieves SOTA results with minimal data requirements.
                </p>
            </div>
        <img id="model" width="100%" src="images/web_fig1.png" ,="" alt="Summary of OPA-DPO">
        <br>
        <br>
        <br>
        <br>
        <div class="content has-text-justified">
            <p>
            <b style="font-size: larger;">Demo of <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" target="_blank">Kullback-Leibler (KL) Divergence</a></b>:
            </p>
            <p>
              Noticed that the initial training objective of DPO is to maximize the reward-model induced by Bradley-Terry model, while constraining the KL divergence between the model and the reference policy.
              To provide an intuitive understanding of the importance of on-policy data, we visualize the KL divergence between the current policy (\(\,\pi_\theta\,\)) and the reference policy (\(\,\pi_{ref}\,\)).
              You can drag the sliders to adjust the mean and variance of the current policy, and observe how the KL divergence changes accordingly.
              In summary, <b>the KL divergence becomes substantially large if the current policy generates tokens that the reference policy never produces</b>.
            </p>
        </div>
        </div>
      </div>
    </div>
    
    <div style="text-align: center; font-size: 20px; color: red;">
        \(KL (\pi_\theta \, || \,\pi_{ref})= \) <span id="kl-divergence">0.000</span>
    </div>
    <br>
    <!-- Legend Section -->
    <div class="legend-container" style="display: flex; justify-content: center; align-items: center; gap: 20px; margin-bottom: 20px;">
        <h3 style="font-size: 16px; color: #333;"> </h3>
        <div class="legend-item" style="display: flex; align-items: center; gap: 8px; font-size: 16px;">
            <span class="legend-color" style="width: 20px; height: 20px; display: inline-block; background-color: #007bff;"></span>
            <span>\(\pi_\theta\)</span>
        </div>
        <div class="legend-item" style="display: flex; align-items: center; gap: 8px; font-size: 16px;">
            <span class="legend-color" style="width: 20px; height: 20px; display: inline-block; background-color: #ff5722;"></span>
            <span>\(\pi_{ref}\)</span>
        </div>
    </div>

    <!-- Chart Section -->
    <div id="chart" style="display: flex; justify-content: center; align-items: flex-end; margin: 40px auto; height: 200px; position: relative; width: calc(44px * 20); border-left: 1px solid #ccc; border-bottom: 1px solid #ccc;"></div>

    <!-- Slider Controls -->
    <div class="slider-controls" style="display: flex; justify-content: center; align-items: center; gap: 20px; margin: 20px 0;">
        <div class="slider-container" style="display: flex; flex-direction: column; align-items: center;">
            <label for="center-slider" style="margin-bottom: 5px; font-size: 14px; color: #333;">Mean of \(\pi_\theta\):</label>
            <input type="range" id="center-slider" min="0" max="30" value="10">
        </div>
        <div class="slider-container" style="display: flex; flex-direction: column; align-items: center;">
            <label for="variance-slider" style="margin-bottom: 5px; font-size: 14px; color: #333;">Var of \(\pi_\theta\):</label>
            <input type="range" id="variance-slider" min="0.5" max="1.5" step="0.1" value="1">
        </div>
    </div>

    <script>
        const numTokens = 30;
        const referenceCenter = 10; // Reference policy center
        const referenceStdDev = 3.5; // Standard deviation of reference policy
        const chart = document.getElementById("chart");
        const klDisplay = document.getElementById("kl-divergence");
        const centerSlider = document.getElementById("center-slider");
        const varianceSlider = document.getElementById("variance-slider");

        let userCenter = parseInt(centerSlider.value); // Initial user policy center
        let userStdDev = parseFloat(varianceSlider.value); // Initial user policy standard deviation

        // Helper function to calculate Gaussian distribution
        function gaussian(x, mean, stdDev) {
            const exponent = -Math.pow(x - mean, 2) / (2 * Math.pow(stdDev, 2));
            return Math.exp(exponent) / (stdDev * Math.sqrt(2 * Math.PI));
        }

        // Create the probability distribution for tokens
        function createDistribution(center, stdDev) {
            const distribution = [];
            let sum = 0;
            for (let i = 0; i < numTokens; i++) {
                const prob = gaussian(i, center, stdDev);
                const filteredProb = prob < 0.00001 ? 0 : prob;
                distribution.push(filteredProb);
                sum += filteredProb;
            }
            return distribution.map(p => p / sum);
        }

        // Calculate KL divergence KL(P || Q)
        function calculateKL(p, q) {
            let kl = 0;
            for (let i = 0; i < p.length; i++) {
                if (p[i] > 0 && q[i] > 0) {
                    kl += p[i] * Math.log(p[i] / q[i]);
                } else if (p[i] > 0 && q[i] === 0) {
                    return Infinity;
                }
            }
            return kl.toFixed(3);
        }

        // Update KL divergence display
        function updateKLDivergence(klValue) {
            if (klValue === Infinity) {
                klDisplay.textContent = "∞";
            } else {
                klDisplay.textContent = klValue.toFixed(3);
            }
        }

        // Render the chart
        function renderChart(referenceDist, userDist) {
            chart.innerHTML = "";
            chart.innerHTML = `
                <div style="position: absolute; width: 100%; height: 1px; background-color: #ccc; left: 0; bottom: 25%;"></div>
                <div style="position: absolute; width: 100%; height: 1px; background-color: #ccc; left: 0; bottom: 50%;"></div>
                <div style="position: absolute; width: 100%; height: 1px; background-color: #ccc; left: 0; bottom: 75%;"></div>
                <div style="position: absolute; left: -30px; bottom: 0; font-size: 12px; color: #666;">0</div>
                <div style="position: absolute; left: -30px; bottom: 25%; font-size: 12px; color: #666;">0.25</div>
                <div style="position: absolute; left: -30px; bottom: 50%; font-size: 12px; color: #666;">0.50</div>
                <div style="position: absolute; left: -30px; bottom: 75%; font-size: 12px; color: #666;">0.75</div>
                <div style="position: absolute; left: -30px; bottom: 100%; font-size: 12px; color: #666;">1.0</div>
            `;
            for (let i = 0; i < numTokens; i++) {
                const bar = document.createElement("div");
                bar.style.cssText = "width: 40px; margin: 0 2px; display: inline-block; position: relative; height: 100%;";
                const refBar = document.createElement("div");
                refBar.style.cssText = `width: 50%; background-color: #ff5722; position: absolute; bottom: 0; left: 0; height: ${referenceDist[i] * 100}%;`;
                bar.appendChild(refBar);
                const userBar = document.createElement("div");
                userBar.style.cssText = `width: 50%; background-color: #007bff; position: absolute; bottom: 0; right: 0; height: ${userDist[i] * 100}%;`;
                bar.appendChild(userBar);
                const label = document.createElement("div");
                label.style.cssText = "position: absolute; bottom: -20px; left: 0; width: 100%; text-align: center; font-size: 12px; color: #666;";
                label.textContent = i;
                bar.appendChild(label);
                chart.appendChild(bar);
            }
        }

        const referenceDist = createDistribution(referenceCenter, referenceStdDev);
        let userDist = createDistribution(userCenter, userStdDev);
        renderChart(referenceDist, userDist);
        klDisplay.textContent = calculateKL(userDist, referenceDist);

        centerSlider.addEventListener("input", (event) => {
            userCenter = parseInt(event.target.value);
            userDist = createDistribution(userCenter, userStdDev);
            renderChart(referenceDist, userDist);
            klDisplay.textContent = calculateKL(userDist, referenceDist);
        });

        varianceSlider.addEventListener("input", (event) => {
            userStdDev = parseFloat(event.target.value);
            userDist = createDistribution(userCenter, userStdDev);
            renderChart(referenceDist, userDist);
            klDisplay.textContent = calculateKL(userDist, referenceDist);
        });
    </script>
    <br>
    <br>
</section>

<section class="section interpolation-panel"; background-color: #f4f4f9; text-align: center;>
    <div class="container is-max-desktop">
        <br>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">Review on Related Algorithms</h2>
              <div class="content has-text-justified">
                  <p>
                  <b style="font-size: larger;">We categorize existing DPO-based algorithms for addressing hallucination issues in LVLMs into 3 classes: </b>
                  </p>
                  <ul>
                    <li>
                        <b>Hallucination Injection:</b> 
                        (<a href="https://arxiv.org/abs/2402.11411" target="_blank">POVID</a>, and <a href="https://arxiv.org/abs/2405.18654v1" target="_blank">HALVA</a>). 
                        The ground-truth response is preferred, while the rejected response contains injected hallucinations. Since the errors do not originate from the model itself, the policy is unlikely to benefit from training.
                    </li>
                    <li>
                        <b>Hallucination Recognition:</b> 
                        (<a href="https://arxiv.org/abs/2312.00849" target="_blank">RLHF-V</a>, <a href="https://arxiv.org/abs/2311.16839" target="_blank">HA-DPO</a> and <a href="https://arxiv.org/abs/2404.14233" target="_blank">HSA-DPO</a>).
                        The model generates responses, after which experts (AI or human) identify errors and make revisions. The off-policy nature of the revised responses makes them challenging to learn effectively.
                    </li>
                    <li>
                        <b>Self Evolution:</b> 
                        (<a href="https://arxiv.org/abs/2405.17220" target="_blank">RLAIF-V</a>). 
                        Both preferred and rejected responses are generated by the initial policy. A superior model assesses hallucinations, preferring the response with fewer errors. However, hallucinations may exist in both responses, thereby affecting the learning efficiency.
                    </li>
                  </ul>
              </div>
          <img id="model" width="100%" src="images/web_fig2.png" ,="" alt="Summary of Related Algorithms">
          </div>
        </div>
        <br>
        <br>
      </div>
</section>

<section class="section"; background-color: #f4f4f9; text-align: center;>
    <div class="container is-max-desktop">
        <br>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">On-Policy Alignment (OPA)-DPO </h2>
              <div class="content has-text-justified">
                  <p>
                  <b style="font-size: larger;">Our proposed OPA-DPO comprises four essential steps:</b>
                  </p>
                    <p>
                      \(\quad\)<b>Step 1:</b> Collect responses from the original policy based on the images and corresponding prompts.
                    </p>
                    <p>
                      \(\quad\)<b>Step 2:</b> Utilize <a href="https://openai.com/contributions/gpt-4v/" target="_blank">GPT-4V</a> to correct any hallucinations in the generated responses with minimal modifications.
                    </p>
                    <p>
                      \(\quad\)<b>Step 3:</b> Conduct <a href="https://arxiv.org/abs/2106.09685" target="_blank">LoRA</a>-SFT on the GT responses and revised responses.
                    </p>
                    <p>
                      \(\quad\)<b>Step 4:</b> Initiate OPA-DPO training from the policy obtained in step 3. Note that we construct extra image-focused and anchored preference pairs following <a href="https://arxiv.org/abs/2406.11839" target="_blank">mDPO</a>.
                    </p>
              </div>
          <img id="model" width="100%" src="images/web_fig3.png" ,="" alt="Implementation of OPA-DPO">
          </div>
        </div>
        <br>
        <br>
      </div>
</section>

<section class="section interpolation-panel"; background-color: #f4f4f9; text-align: center;>
    <div class="container is-max-desktop">
        <br>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">Experimental Results</h2>
              <div class="content has-text-justified">
                  <p>
                  <b style="font-size: larger;">Hallucination Bench Evaluations:</b>
                  </p>
                    <p>
                      \(\quad\)<b><a href="https://arxiv.org/abs/2311.07397" target="_blank">AMBER</a>:</b> A benchmark with detailed object annotations, featuring 1004 images in a generative task. Using the official codebase, we evaluate CHAIR score, object coverage, hallucination rate, and alignment with human cognition.
                    </p>
                    <p>
                      \(\quad\)<b><a href="https://arxiv.org/abs/2309.14525" target="_blank">MMHalBench</a>:</b> A question-answering benchmark with 96 images across 12 object categories. Following the official protocol, we use GPT-4 to rate responses from zero to six, calculating hallucination rate by the proportion of responses rated below three.
                    </p>
                    <p>
                      \(\quad\)<b><a href="https://arxiv.org/abs/1809.02156" target="_blank">Object HalBench</a>:</b> A widely used benchmark for assessing object hallucination. We evaluate across 300 instances using the <a href="https://arxiv.org/abs/2312.00849" target="_blank">RLHF-V</a> codebase, reporting hallucination rates at both response (CHAIRs) and object levels (CHAIRi).
                    </p>
                    <p>
                      \(\quad\)<b><a href="https://arxiv.org/abs/2305.10355" target="_blank">POPE</a>:</b> A yes/no question-answering benchmark for object hallucination evaluation. We report accuracy and precision on its Adversarial set, consisting of 3000 cases.
                    </p>
              </div>
                <img id="model" width="100%" src="images/web_fig4.png" ,="" alt="Experimental Results">
              <br>
              <br>
              <br>
              <div class="content has-text-justified">
                  <p>
                  <b style="font-size: larger;">Ablation Studies</b>:
                  </p>
              </div>
                <img id="model" width="100%" src="images/web_fig5.png" ,="" alt="Ablation Study">
          </div>
        </div>
        <br>
        <br>
      </div>
</section>
  
  
  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Qualitative Examples</h2>
      </div>
    </div>
    <!--/ Results. -->
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <div class="content has-text-justified">
            <ul>
              <li><b>Image description tasks:</b> OPA-DPO helps to significantly reduce hallucination issues. Nevertheless, we have observed that models trained with the OPA-DPO framework tend to adopt a slightly conservative strategy, often disregarding some insignificant details.</li>
            </ul>
          </div>
          <img src="images/web_fig6.png" width="90%" alt="">
          <br>
          <br>
          <img src="images/web_fig7.png" width="90%" alt="">
          <div class="content has-text-justified">
            <ul>
              <li><b>False premise queries:</b> An interesting phenomenon we observed is that LVLMs consistently exhibit hallucinations when presented with queries based on false premises. These queries include objects or details that either do not exist in the image or are irrelevant to it. OPA-DPO can partially mitigate this issue.</li>
            </ul>
          </div>
          <img src="images/web_fig8.png" width="90%" alt="">
          <br>
          <br>
        </div>
        <!-- <div class="box"><div class="pic"><img src="demos/p7.png" alt=""></div></div>
        <div class="box"><div class="pic"><img src="demos/p8.png" alt=""></div></div>
        <div class="box"><div class="pic"><img src="demos/p9.png" alt=""></div></div> -->
      </div>
    </div>
  </section>
  
  <section class="section interpolation-panel" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">BibTeX</h2>
      </div>
      <pre><code>
        @article{yang2025opadpo,
            title={Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key},
            author={Yang, Zhihe and Luo, Xufang and Han, Dongqi and Xu, Yunjian and Li, Dongsheng},
            journal={arXiv preprint arXiv:2501.09695},
            year={2025}
          }
  </code></pre>
    <div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Acknowledgement</h2>
    </div>
    <div style="text-align: left; width: 90%; margin: 0 auto;">
      We would like to express our gratitude for the code snippets provided in 
      <a href="https://llava-vl.github.io/" target="_blank">LLaVA</a>, 
      <a href="https://llava-rlhf.github.io/" target="_blank">LLaVA-RLHF</a>, 
      <a href="https://github.com/lm-sys/FastChat" target="_blank">FastChat</a>, 
      <a href="https://github.com/huggingface/trl" target="_blank">TRL</a>, and datasets provided in 
      <a href="https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset" target="_blank">RLAIF-V</a>. 
      These resources have significantly contributed to the development of our project.
    </div>
    </div>
  </section>
  
  <!--
  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Acknowledgement</h2>
      <p>
        This website is adapted from <a
        href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </div>
  </section>
   -->
  
  
  
  <script src="js/Underscore-min.js"></script>
  <script src="js/index.js"></script>
  
  
  
  
  
  
  <div id="c4g-content-root" class="c4g-widget"></div></body></html>
